version: "3.9"

services:
  db:
    deploy:
      # To use an external database, set replicas to 0 and set DATABASE_URL to the external database url in the .env file
      replicas: 1
    image: postgres:14
    restart: unless-stopped
    volumes:
      - /mnt/cache/appdata/postgresql14_windmill:/var/lib/postgresql/data
    ports:
      - 5433:5432
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: windmill
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  windmill_server:
    image: ${WM_IMAGE}
    pull_policy: always
    deploy:
      replicas: 1
    restart: unless-stopped
    ports:
      - 7420:8000
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - BASE_URL=${WM_BASE_URL}
      - RUST_LOG=info
      ## You can set the number of workers to 1 and not need any separate worker service but not recommended
      - NUM_WORKERS=0
      - DISABLE_SERVER=false
      - METRICS_ADDR=false
      - REQUEST_SIZE_LIMIT=${WM_REQUEST_SIZE_LIMIT}
      # LICENSE_KEY is only needed for the enterprise edition
      #- LICENSE_KEY=${WM_LICENSE_KEY}
      - OAUTH_JSON_AS_BASE64=$(base64 oauth.json | tr -d '\n')
    depends_on:
      db:
        condition: service_healthy

  windmill_worker:
    image: ${WM_IMAGE}
    pull_policy: always
    deploy:
      replicas: 3
    restart: unless-stopped
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - BASE_URL=${WM_BASE_URL}
      - RUST_LOG=info
      - DISABLE_SERVER=true
      - KEEP_JOB_DIR=false
      - METRICS_ADDR=false
      # To handle all tags, remove the env variable altogether. If you do so, you can remove the windmill_worker_native containers.
      - WORKER_TAGS=deno,python3,go,bash,dependency,flow,hub,other,bun
      # LICENSE_KEY is only needed for the enterprise edition
      #- LICENSE_KEY=${WM_LICENSE_KEY}
      - OAUTH_JSON_AS_BASE64=$(base64 oauth.json | tr -d '\n')
    depends_on:
      db:
        condition: service_healthy
    # to mount the worker folder to debug, KEEP_JOB_DIR=true and mount /tmp/windmill
    volumes:
      # mount the docker socket to allow to run docker containers from within the workers
      - /var/run/docker.sock:/var/run/docker.sock
      - /mnt/cache/appdata/worker_dependency_cache:/tmp/windmill/cache

  ## This worker is specialized for "native" jobs. They run in-process and can thus be parallelized to more than 1 at a time on a given worker which is why NUM_WORKERS is set to 4
  windmill_worker_native:
    # Use ghcr.io/windmill-labs/windmill-ee:main for the ee
    image: ${WM_IMAGE}
    pull_policy: always
    deploy:
      replicas: 1
      resources:
          limits:
            cpus: "0.25"
            memory: 512M
    restart: unless-stopped
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - BASE_URL=${WM_BASE_URL}
      - RUST_LOG=info
      - DISABLE_SERVER=true
      - KEEP_JOB_DIR=false
      - METRICS_ADDR=false
      - NUM_WORKERS=4
      - WORKER_TAGS=nativets,postgresql,mysql,graphql
      # LICENSE_KEY is only needed for the enterprise edition
      #- LICENSE_KEY=${WM_LICENSE_KEY}
      - OAUTH_JSON_AS_BASE64=$(base64 oauth.json | tr -d '\n')
    depends_on:
      db:
        condition: service_healthy

  lsp:
    image: ghcr.io/windmill-labs/windmill-lsp:latest
    restart: unless-stopped
    expose:
      - 3001
    volumes:
      - /mnt/cache/appdata/lsp_cache:/root/.cache

  multiplayer:
    image: ghcr.io/windmill-labs/windmill-multiplayer:latest
    deploy:
      replicas: 0 # Set to 1 to enable multiplayer, only available on Enterprise Edition
    restart: unless-stopped
    expose:
      - 3002